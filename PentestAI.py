from ctransformers import AutoModelForCausalLM
from transformers import AutoTokenizer
from colorama import Fore
import torch
import subprocess
import os
import re
import logging
import concurrent.futures
import signal

# Set up logging for tracking actions
logging.basicConfig(filename='pentest_ai_log.txt', level=logging.INFO, format='%(asctime)s - %(message)s')

# Timeout handler for command execution
def timeout_handler(signum, frame):
    raise TimeoutError("Command execution timed out.")

# IP address validation
def validate_ip(ip):
    pattern = re.compile(r"^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$")
    if not pattern.match(ip):
        print(Fore.RED + "Invalid IP address format. Please try again." + Fore.WHITE)
        return False
    return True

# Check and install necessary tools
def check_and_install_tools(tools):
    print(Fore.YELLOW + "Checking for necessary pentesting tools..." + Fore.WHITE)
    for tool in tools:
        result = subprocess.run(['which', tool], stdout=subprocess.PIPE)
        if not result.stdout.strip():
            print(Fore.RED + f"{tool} is not installed. Installing..." + Fore.WHITE)
            subprocess.run(['sudo', 'apt-get', 'install', '-y', tool])
        else:
            version_result = subprocess.run([tool, '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            logging.info(f"{tool} version: {version_result.stdout.decode('utf-8').strip()}")

    print(Fore.GREEN + "All necessary tools are installed." + Fore.WHITE)

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained("ArmurAI/Pentest_AI")
model_path = "<path>/Pentest_LLM.gguf"
model = AutoModelForCausalLM.from_pretrained(model_path, gpu_layers=16, threads=1, context_length=4096, max_new_tokens=-1)

# Encode prompt for the model
def encode_prompt(role, prompt):
    return tokenizer.encode(f"{role}\n{prompt}\n")

def start_prompt(role):
    return f"{role}\n"

# Assistant job description for initial setup
assistant_job = (
    "you are PentestAI, users expert system for penetration testing guidance. "
    "your role is to deliver precise, actionable instructions and the exact commands needed for each phase of the pentest. "
    "you dynamically update the pentesting steps based on users progress and feedback, ensuring an efficient approach. "
    "you can automatically execute commands in a Kali Linux environment."
)

# Encode the assistant job to prime the model
toks = encode_prompt("assistant", assistant_job)

# Intro message
intro_message = (
    "Welcome to PentestAI. Provide the IP address of the target machine, and PentestAI will offer tailored advice for each phase. "
    "Type 'exit' or 'hacked' to stop."
)
print(Fore.CYAN + intro_message + Fore.WHITE)

pentest_tools = ['nmap', 'metasploit-framework', 'john', 'wireshark', 'aircrack-ng', 'hydra', 'burpsuite', 'sqlmap', 'nikto', 'gobuster']
check_and_install_tools(pentest_tools)

system_prompt = "Please provide the IP address of the target machine."
print(Fore.CYAN + system_prompt + Fore.WHITE)
toks += encode_prompt("system", system_prompt)

prompt = True

# Get and validate IP address
ip_address = input(Fore.YELLOW + "Enter the IP address of the target machine: " + Fore.WHITE)
while not validate_ip(ip_address):
    ip_address = input(Fore.YELLOW + "Enter a valid IP address: " + Fore.WHITE)
    
toks += encode_prompt("user", ip_address)

# Execute tool command with timeout and parallel processing
def execute_tool_command(output, ip_address):
    tool_commands = {
        'nmap': f'nmap -sV {ip_address}',
        'metasploit': f'msfconsole -q -x "use exploit/multi/handler; set LHOST {ip_address}; run"',
        'john': 'john --list=formats',
        'wireshark': 'wireshark -k -i eth0',
        'aircrack-ng': 'airmon-ng start wlan0',
        'hydra': f'hydra -L user.txt -P pass.txt {ip_address} ssh',
        'burpsuite': 'burpsuite',
        'sqlmap': f'sqlmap -u "http://{ip_address}" --batch',
        'nikto': f'nikto -h http://{ip_address}',
        'gobuster': f'gobuster dir -u http://{ip_address} -w /path/to/wordlist',
    }

    for tool, command in tool_commands.items():
        if tool in output:
            print(Fore.GREEN + f"Executing {tool} command:" + Fore.WHITE)
            try:
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(30)  # Timeout after 30 seconds
                command_output = subprocess.run(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                signal.alarm(0)
                logging.info(f"Output for {tool}:\n{command_output.stdout.decode()}")
                print(Fore.GREEN + f"Output for {tool}:\n{command_output.stdout.decode()}" + Fore.WHITE)
            except TimeoutError:
                print(Fore.RED + f"{tool} command timed out." + Fore.WHITE)
            return command_output.stdout.decode()
    return ""

# Run the assistant loop
while prompt:
    toks += tokenizer.encode(start_prompt("assistant"))
    print(Fore.CYAN + "Assistant: " + Fore.WHITE, end="")

    new_toks = []
    for tok in model.generate(torch.tensor(toks)):
        new_toks += [tok]
        char = str(model.detokenize(tok))
        print(char, end="", flush=True)

    toks += new_toks
    assistant_output = tokenizer.decode(new_toks)

    # Parallel execution of tools
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(execute_tool_command, assistant_output, ip_address)
        command_output = future.result()

    if command_output:
        toks += encode_prompt("assistant", command_output)
    else:
        user_input = input(Fore.YELLOW + "\nUser (result/next step): " + Fore.WHITE)
        if user_input.lower() == 'exit' or user_input.lower() == 'hacked':
            prompt = False
        else:
            toks += encode_prompt("user", user_input)
